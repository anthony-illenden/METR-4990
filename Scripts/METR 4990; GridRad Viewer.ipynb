{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from metpy.plots import USCOUNTIES\n",
    "import cartopy.crs as ccrs \n",
    "import cartopy.feature as cfeature\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "import metpy\n",
    "import os\n",
    "import scipy.ndimage as ndimage\n",
    "import pandas as pd\n",
    "from metpy.plots import StationPlot\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A couple functions are from Tim Supinie's gridradpy repository on GitHub (https://github.com/tsupinie/gridradpy/tree/main) with some modifications ##\n",
    "\n",
    "_index_variables = ['Reflectivity', 'wReflectivity', 'SpectrumWidth', 'wSpectrumWidth', 'AzShear', 'wAzShear', \n",
    "                    'Divergence', 'wDivergence', 'DifferentialReflectivity', 'wDifferentialReflectivity',\n",
    "                    'DifferentialPhase', 'wDifferentialPhase', 'CorrelationCoefficient', 'wCorrelationCoefficient']\n",
    "\n",
    "def read_file(infile: Union[str, Path]) -> xr.Dataset:\n",
    "    ds = xr.open_dataset(infile)\n",
    "\n",
    "    nlon = ds.dims['Longitude']\n",
    "    nlat = ds.dims['Latitude']\n",
    "    nalt = ds.dims['Altitude']\n",
    "\n",
    "    index = ds['index'].values\n",
    "\n",
    "    da_dict = {}\n",
    "    for var in _index_variables:\n",
    "        if var not in ds.variables:\n",
    "            continue\n",
    "\n",
    "        # Create arrays to store binned values for reflectivity at horizontal polarization\n",
    "        values    = np.zeros(nlon * nlat * nalt, dtype=np.float32)\n",
    "        values[:] = np.nan\n",
    "\n",
    "        # Add values to arrays\n",
    "        values[index[:]]  =  ds[var].values[:]\n",
    "        da = xr.DataArray(data=values.reshape((nalt, nlat, nlon)), coords=ds['Nradobs'].coords, \n",
    "                          dims=ds['Nradobs'].dims, name=ds[var].name, attrs=ds[var].attrs)\n",
    "\n",
    "        da_dict[var] = da\n",
    "\n",
    "    ds = ds.assign(**da_dict)\n",
    "\n",
    "    return ds.drop_vars('index')\n",
    "\n",
    "# GridRad filter routine\n",
    "def filter(ds: xr.Dataset, wthresh=1.5, freq_thresh=0.6, Z_H_thresh=15.0, nobs_thresh=2):\n",
    "    \"\"\"\n",
    "    wthresh:        Bin weight threshold for filtering by year (dimensionless)\n",
    "    freq_thresh:    Echo frequency threshold (dimensionless)\n",
    "    Z_H_thresh:     Reflectivity threshold (dBZ)\n",
    "    nobs_thresh:    Number of observations threshold\n",
    "    \"\"\"\n",
    "\n",
    "    has_data = ds['Nradobs'] > 0\n",
    "    echo_frequency = (ds['Nradecho'] / ds['Nradobs']).where(has_data, 0.)\n",
    "\n",
    "    # Find observations with low weight\n",
    "    mask = ~(((ds['wReflectivity'] < wthresh) & (ds['Reflectivity'] < Z_H_thresh)) |\n",
    "             ((echo_frequency < freq_thresh) & (ds['Nradobs'] > nobs_thresh)))\n",
    "    \n",
    "    # Remove low confidence observations\n",
    "    if has_data.any():\n",
    "        da_dict = {}\n",
    "        for var in _index_variables:\n",
    "            if var.startswith('w') or var not in ds.variables:\n",
    "                continue\n",
    "            \n",
    "            da_dict[var] = ds[var].where(mask)\n",
    "\n",
    "        ds = ds.assign(**da_dict)\n",
    "    \n",
    "    # Return filtered data0\n",
    "    return ds\n",
    "\n",
    "# Gridrad clutter filter routine\n",
    "def remove_clutter(ds: xr.Dataset, skip_weak_ll_echo=False, areal_coverage_thresh=0.32) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    areal_coverage_thresh:  Fractional areal coverage threshold for speckle identification\n",
    "    \"\"\"\n",
    "    \n",
    "    da = ds['Reflectivity']\n",
    "    clutter = xr.DataArray(data=np.zeros_like(da.values, dtype=bool), coords=da.coords, dims=da.dims)\n",
    "\n",
    "    # Light pass at a correlation coefficient decluttering approach first\n",
    "    if 'DifferentialReflectivity' in ds.variables:\n",
    "        cc_clutter = (((ds['Reflectivity'] < 40.) & (ds['CorrelationCoefficient'] < 0.9)) | \n",
    "                      ((ds['Reflectivity'] < 25.) & (ds['CorrelationCoefficient'] < 0.95) & (ds['Altitude'] > 10.)))\n",
    "\n",
    "\t\t\t        \n",
    "    # First pass at removing speckles\n",
    "    # TAS: This is slightly different than the original. It fills the boundaries with the nearest neighbor instead of \n",
    "    #   wrapping around to the other side of the domain\n",
    "    has_refl_data = ~ds['Reflectivity'].where(~clutter).isnull()\n",
    "    cover = (has_refl_data.rolling(Longitude=5, Latitude=5, center=True).mean()\n",
    "                          .ffill(dim='Longitude').bfill(dim='Longitude')\n",
    "                          .ffill(dim='Latitude').bfill(dim='Latitude'))\n",
    "    speckle = cover <= areal_coverage_thresh\n",
    "    clutter = clutter | speckle\n",
    "\n",
    "    # Attempts to mitigate ground clutter and biological scatterers\n",
    "    if not skip_weak_ll_echo:\n",
    "        # Find weak low-level echoes\n",
    "        weakref_clutter = ((ds['Reflectivity'].where(~clutter) < 10.) & (ds['Altitude'] <= 4.))\n",
    "        clutter = clutter | weakref_clutter\n",
    "\n",
    "        # Second check for weak, low-level echo\n",
    "        refl_da = ds['Reflectivity'].where(~clutter)\n",
    "        refl_max = refl_da.max(dim='Altitude')\n",
    "        echo0_min  = ((refl_da >  0.) * ds['Altitude']).min(dim='Altitude')\n",
    "        echo0_max  = ((refl_da >  0.) * ds['Altitude']).max(dim='Altitude')\n",
    "        echo5_max  = ((refl_da >  5.) * ds['Altitude']).max(dim='Altitude')\n",
    "        echo15_max = ((refl_da > 15.) * ds['Altitude']).max(dim='Altitude')\n",
    "        \n",
    "        # Find weak and/or shallow echo\n",
    "        col_mask = (((refl_max   <  20.) & (echo0_max  <= 4.) & (echo0_min  <= 3.)) |\n",
    "                    ((refl_max   <  10.) & (echo0_max  <= 5.) & (echo0_min  <= 3.)) |\n",
    "                    ((echo5_max  <=  5.) & (echo5_max  >  0.) & (echo15_max <= 3.)) |\n",
    "                    ((echo15_max <   2.) & (echo15_max >  0.)))\n",
    "\n",
    "        clutter = clutter | col_mask\n",
    "\n",
    "    # Find clutter below convective anvils\n",
    "    # TAS: The original code cuts off the topmost horizontal slice of the above- and below-4-km layers. I'm guessing \n",
    "    #   that's not correct.\n",
    "    alt_cutoff = 4.\n",
    "    has_refl_data = ~ds['Reflectivity'].where(~clutter).isnull()\n",
    "    anvil_clutter = ((has_refl_data.sel(Altitude=alt_cutoff) == False) & \n",
    "                     (has_refl_data.sel(Altitude=slice(None, alt_cutoff)).sum(dim='Altitude') > 0) &\n",
    "                     (has_refl_data.sel(Altitude=slice(alt_cutoff, None)).sum(dim='Altitude') > 0) &\n",
    "                     (ds['Altitude'] <= alt_cutoff))\n",
    "\n",
    "    clutter = clutter | anvil_clutter\n",
    "    \n",
    "    # Second pass at removing speckles\n",
    "    has_refl_data = ~ds['Reflectivity'].where(~clutter).isnull()\n",
    "    cover = (has_refl_data.rolling(Longitude=5, Latitude=5, center=True).mean()\n",
    "                          .ffill(dim='Longitude').bfill(dim='Longitude')\n",
    "                          .ffill(dim='Latitude').bfill(dim='Latitude'))\n",
    "    speckle = cover <= areal_coverage_thresh\n",
    "    clutter = clutter | speckle\n",
    "\n",
    "    # Remove the clutter from all variables\n",
    "    da_dict = {}\n",
    "    for var in _index_variables:\n",
    "        if var.startswith('w') or var not in ds.variables:\n",
    "            continue\n",
    "        \n",
    "        da_dict[var] = ds[var].where(~clutter)\n",
    "\n",
    "    ds = ds.assign(**da_dict)\n",
    "    \n",
    "    return ds\n",
    "\n",
    "def plot_image(ds):\n",
    "    cmap = metpy.plots.ctables.registry.get_colortable('NWSReflectivity')\n",
    "    ref = ds['Reflectivity'].sel(Altitude=3)\n",
    "    lons = ds['Longitude']\n",
    "    lats = ds['Latitude']\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6),subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "    ax.set_extent([-94.5, -83, 41, 49])\n",
    "    ax.add_feature(cfeature.COASTLINE.with_scale('50m'), linewidth=0.5)\n",
    "    ax.add_feature(cfeature.STATES, linewidth=0.5)\n",
    "    ax.add_feature(USCOUNTIES.with_scale('5m'), linewidth=0.25)\n",
    "    ax.add_feature(cfeature.BORDERS, linewidth=0.5)\n",
    "\n",
    "    plt.pcolormesh(ds['Longitude'], ds['Latitude'], ref, cmap=cmap, vmin=0, vmax=75)\n",
    "    plt.colorbar(shrink=0.85, label='dBZ')\n",
    "    plt.title('{} {}z'.format(ref.name, ds['time'].dt.strftime('%Y-%m-%d %H:%M:%S').values[0]))\n",
    "    ax.set_xlabel(\"X_axis_title\")\n",
    "    #plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    ax.gridlines(draw_labels=True, color='black',linestyle='--', alpha=0.35)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('METR_4990_GridRad_{}_{}z'.format(ref.name, ds['time'].dt.strftime('%Y-%m-%d_%H-%M-%S').values[0]), dpi=450)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'C:\\\\Users\\\\Tony\\\\Desktop\\\\METR 4990\\\\gridraddata3'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".nc\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        ds = read_file(file_path)\n",
    "        ds = filter(ds)\n",
    "        ds = remove_clutter(ds, skip_weak_ll_echo=True)\n",
    "        plot_image(ds)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
